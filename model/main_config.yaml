"team_name": "NNNandAnders" # Your team name
"eval_method": ["mcqa", "rag"] # mcqa, reward, rag, compression
"task_type": "causal_lm" # causal_lm, seq2seq
"policy_model_path": "./checkpoints/m3/checkpoint-10000/" # Your path to the final checkpoint
"reference_model_path": "meta-llama/Meta-Llama-3-8B-Instruct" # The repo id of your pretrained reference model
"quantized_policy_model_path": "./documents/quantized_model/" # Your path to the final quantized checkpoint
"rag_policy_model_path": "./checkpoints/m3/checkpoint-10000/" # Your path to the final RAG checkpoint
"test_data_path": "datasets/MCQA/inference_mcqa.jsonl" # Your path to the test data
"dpo_model_args": null # Put any model arguments required to load your DPO model below
"rag_model_args": # Put any model arguments required to load your rag model below
"encoder_model_path": null
"retriever_model_path": "./checkpoints/rag_retriever"
"document_dir": "./data/documents"
"quantized_model_args": {"load_in_4bit":True} # Put any model arguments required to load your quantized model below
